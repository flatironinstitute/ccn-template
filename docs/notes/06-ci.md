# Continuous integration

- readthedocs will handle docs building.
- Jenkins with Flatiron cluster for any tests requiring GPUs or more time/resources than can be obtained through Github actions.
- Github actions for everything else (see [here](https://docs.github.com/en/actions/using-github-hosted-runners/about-github-hosted-runners#supported-runners-and-hardware-resources)) for resources):
  - use `matrix` to test on multiple python versions and OSs.
  - `pytest tests/`, see [here](https://docs.pytest.org/en/7.3.x/)
  - that all notebooks can run (only done on github actions if using `.ipynb` files, but done by readthedocs for mkdocs-gallery)
    - for notebooks that take too long to run on runners, use [papermill](https://papermill.readthedocs.io/en/latest/usage-parameterize.html) to parametrize them to reduce runtime
  - running linters with `tox`
  - generating test coverage report: `coveralls`. any PR must maintain or increase coverage in order to be merged.
  - use [alls-green](https://github.com/re-actors/alls-green) or similar ot check that all tests ran successfully (so only have a single check for branch protection rule)
  - think about how frequently to run tests. one good possibility: weekly, manually, and on every PR:
  ```
  on:
  workflow_dispatch:
  schedule:
  - cron: 0 0 * * 0     # weekly
  pull_request:
    branches:
    - main
    - development
  ```
  - trigger the [connect.yml](https://github.com/flatironinstitute/ccn-template/blob/main/.github/workflows/connect.yml) github action for debuging, it will allow you to ssh connect to the runner
  - deploy to `pypi` on release (test using `test.pypi.org`, test installation and tests run, then deploy)

## Code coverage

Code coverage refers to the measurement of how much of a codebase is tested by automated tests. Ideally, all code should be tested so that any changes can be verified to not break anything. In practice, this is not always possible, but it is still a good idea to aim for high coverage.

To collect coverage locally, run the following command at the root of the project

```bash
pytest --cov-report=xml --cov-report=term tests/
```

This will run the tests, write a coverage summary to the terminal, and generate a `coverage.xml report`. This `.xml` file can be uploaded to [codecov.io](https://codecov.io) (a free service for open source public projects) to generate an online report and coverage badge for the main README.md. Ut can also be utilized by editors like VSCode to show coverage in the editor.

To configure GitHub actions to automatically run coverage and upload the results to codecov.io, add something like the following to `.github/workflows/coverage.yml`:

```yaml
name: coverage
on:
  workflow_dispatch:
  push:
    branches:
    - main
    - development
  pull_request:
    branches:
    - main
    - development

jobs:
  coverage:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v3
        with:
          ref: ${{ github.ref }}

      - name: Install
        run: |
          python -m pip install --upgrade pip
          python -m pip install -e .

      - name: Install packages needed for tests and coverage
        run: pip install pytest pytest-cov
      
      - name: Run tests and create coverage report
        run: |
          pytest --cov-report=xml --cov-report=term tests/

      - name: Upload coverage to codecov.io
        uses: codecov/codecov-action@v3
        with:
          token: ${{ secrets.CODECOV_TOKEN }}
          file: ./coverage.xml
          flags: unittests
```

You will need to set the `CODECOV_TOKEN` secret in the repository settings on GitHub. This can be obtained from codecov.io. Follow the [instructions here](https://docs.codecov.com/docs/quick-start) for information on how to do this.

Once the above GitHub workflow has run successfully, you can add a [coverage status badge](https://docs.codecov.com/docs/status-badges) to your main README.md file. This will show visitors the current coverage level of the project.